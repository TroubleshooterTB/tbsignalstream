"""
Alpha-Ensemble Strategy with Dynamic Nifty 200 Screener
========================================================

Layer 1: Market Alignment & Sectoral Filter
Layer 2: High-Frequency Screener (Top 25 from Nifty 200)
Layer 3: Retest Entry Logic (Sniper Execution)
Layer 4: Risk Management (2.5:1 R:R, Break-Even Trailing)

Mathematical Edge: 40-45% Win Rate achieves profitability with 2.5:1 R:R
Œ¶ (Expectancy) = (Win Rate √ó Avg Win) - (Loss Rate √ó Avg Loss)
"""

import pandas as pd
import numpy as np
from datetime import datetime, time, timedelta
import logging
import requests
import time as time_module
from typing import List, Dict, Tuple, Optional
import ta

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AlphaEnsembleScreener:
    """
    Advanced screening system for Nifty 200 stocks
    Identifies top 25 intraday opportunities using multi-layer filtering
    """
    
    def __init__(self, api_key: str, jwt_token: str):
        self.api_key = api_key
        self.jwt_token = jwt_token
        
        # ===== SCREENING PARAMETERS (LAYER 1 & 2) =====
        self.NIFTY_ALIGNMENT_THRESHOLD = 0.3  # Nifty/Sector must move >0.3% from open
        self.ATR_MIN_PERCENT = 1.0  # Minimum volatility (excludes dead stocks)
        self.ATR_MAX_PERCENT = 4.0  # Maximum volatility (excludes hyper-volatile)
        self.ADX_MIN_TRENDING = 25  # ADX must be >25 (strong trend)
        self.VOLUME_MULTIPLIER = 2.0  # Volume must be >2x average for time-of-day
        self.SCREENING_TIME = time(10, 30)  # Screen at 10:30 AM
        self.TOP_N_CANDIDATES = 25  # Select top 25 stocks
        
        # ===== RETEST ENTRY LOGIC (LAYER 3) =====
        self.EMA_20_PERIOD = 20  # 5-min EMA for retest
        self.VWAP_RETEST_TOLERANCE = 0.1  # 0.1% tolerance for VWAP/EMA touch
        self.DR_START_TIME = time(9, 30)
        self.DR_END_TIME = time(10, 30)
        
        # ===== RISK MANAGEMENT (LAYER 4) =====
        self.RISK_REWARD_RATIO = 2.5  # 1:2.5 R:R (requires 40% WR)
        self.ATR_MULTIPLIER_FOR_SL = 1.5  # SL = 1.5x ATR or retest candle
        self.MAXIMUM_SL_PERCENT = 0.7  # Max SL cap: 0.7%
        self.RISK_PER_TRADE_PERCENT = 1.0  # Risk 1% per trade
        self.BREAKEVEN_RATIO = 1.0  # Move SL to BE at 1:1 R:R
        self.SLIPPAGE_PERCENT = 0.05  # 0.05% slippage + tax buffer
        
        # ===== MARKET HOURS =====
        self.SESSION_END_TIME = time(15, 15)
        
        # Nifty 200 constituents (top 200 stocks by market cap)
        self.NIFTY_200_SYMBOLS = self._get_nifty_200_list()
    
    def _get_nifty_200_list(self) -> List[Dict]:
        """
        Returns Nifty 200 constituent list with tokens
        Loads from JSON file (generated by fetch_nifty200_symbols.py)
        Falls back to subset if file not found
        """
        import json
        import os
        
        # Try loading from JSON file first
        json_file = 'nifty200_constituents.json'
        
        if os.path.exists(json_file):
            try:
                with open(json_file, 'r') as f:
                    nifty_200 = json.load(f)
                
                logger.info(f"üìä Loaded {len(nifty_200)} Nifty 200 constituents from {json_file}")
                return nifty_200
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error loading {json_file}: {e}")
        
        # Fallback: Use Nifty 50 subset for testing
        logger.warning(f"‚ö†Ô∏è {json_file} not found - using Nifty 50 subset")
        logger.warning("‚ö†Ô∏è Run 'python fetch_nifty200_symbols.py' to generate complete list")
        
        nifty_50_subset = [
            # NIFTY 50 (for testing when full list unavailable)
            {'symbol': 'RELIANCE-EQ', 'token': '2885', 'sector': 'ENERGY'},
            {'symbol': 'HDFCBANK-EQ', 'token': '1333', 'sector': 'BANK'},
            {'symbol': 'INFY-EQ', 'token': '1594', 'sector': 'IT'},
            {'symbol': 'ICICIBANK-EQ', 'token': '4963', 'sector': 'BANK'},
            {'symbol': 'TCS-EQ', 'token': '11536', 'sector': 'IT'},
            {'symbol': 'KOTAKBANK-EQ', 'token': '1922', 'sector': 'BANK'},
            {'symbol': 'BHARTIARTL-EQ', 'token': '10604', 'sector': 'TELECOM'},
            {'symbol': 'HINDUNILVR-EQ', 'token': '1394', 'sector': 'FMCG'},
            {'symbol': 'ITC-EQ', 'token': '1660', 'sector': 'FMCG'},
            {'symbol': 'LT-EQ', 'token': '11483', 'sector': 'CAPITAL_GOODS'},
            {'symbol': 'AXISBANK-EQ', 'token': '5900', 'sector': 'BANK'},
            {'symbol': 'ASIANPAINT-EQ', 'token': '236', 'sector': 'CONSUMER_DURABLES'},
            {'symbol': 'MARUTI-EQ', 'token': '10999', 'sector': 'AUTO'},
            {'symbol': 'SUNPHARMA-EQ', 'token': '3351', 'sector': 'PHARMA'},
            {'symbol': 'TITAN-EQ', 'token': '3506', 'sector': 'CONSUMER_DURABLES'},
            {'symbol': 'BAJFINANCE-EQ', 'token': '317', 'sector': 'FINANCIAL_SERVICES'},
            {'symbol': 'ULTRACEMCO-EQ', 'token': '11532', 'sector': 'CEMENT'},
            {'symbol': 'NESTLEIND-EQ', 'token': '17963', 'sector': 'FMCG'},
            {'symbol': 'WIPRO-EQ', 'token': '3787', 'sector': 'IT'},
            {'symbol': 'HCLTECH-EQ', 'token': '7229', 'sector': 'IT'},
            {'symbol': 'M&M-EQ', 'token': '2031', 'sector': 'AUTO'},
            {'symbol': 'TATAMOTORS-EQ', 'token': '3456', 'sector': 'AUTO'},
            {'symbol': 'NTPC-EQ', 'token': '11630', 'sector': 'POWER'},
            {'symbol': 'ONGC-EQ', 'token': '2475', 'sector': 'ENERGY'},
            {'symbol': 'TECHM-EQ', 'token': '13538', 'sector': 'IT'},
            {'symbol': 'HINDALCO-EQ', 'token': '1363', 'sector': 'METALS'},
            {'symbol': 'ADANIENT-EQ', 'token': '25', 'sector': 'DIVERSIFIED'},
            {'symbol': 'TATASTEEL-EQ', 'token': '3499', 'sector': 'METALS'},
            {'symbol': 'CIPLA-EQ', 'token': '694', 'sector': 'PHARMA'},
            {'symbol': 'BAJAJFINSV-EQ', 'token': '16675', 'sector': 'FINANCIAL_SERVICES'},
            {'symbol': 'COALINDIA-EQ', 'token': '20374', 'sector': 'METALS'},
            {'symbol': 'DRREDDY-EQ', 'token': '881', 'sector': 'PHARMA'},
            {'symbol': 'EICHERMOT-EQ', 'token': '910', 'sector': 'AUTO'},
            {'symbol': 'HEROMOTOCO-EQ', 'token': '1348', 'sector': 'AUTO'},
            {'symbol': 'APOLLOHOSP-EQ', 'token': '157', 'sector': 'HEALTHCARE'},
            {'symbol': 'DIVISLAB-EQ', 'token': '10940', 'sector': 'PHARMA'},
            {'symbol': 'INDUSINDBK-EQ', 'token': '5258', 'sector': 'BANK'},
            {'symbol': 'TATACONSUM-EQ', 'token': '3432', 'sector': 'FMCG'},
            {'symbol': 'GRASIM-EQ', 'token': '1232', 'sector': 'DIVERSIFIED'},
            {'symbol': 'BRITANNIA-EQ', 'token': '547', 'sector': 'FMCG'},
            {'symbol': 'BAJAJ-AUTO-EQ', 'token': '16669', 'sector': 'AUTO'},
            {'symbol': 'ADANIPORTS-EQ', 'token': '15083', 'sector': 'INFRASTRUCTURE'},
            {'symbol': 'BPCL-EQ', 'token': '526', 'sector': 'ENERGY'},
            {'symbol': 'UPL-EQ', 'token': '11287', 'sector': 'AGRO_CHEMICALS'},
            {'symbol': 'SBILIFE-EQ', 'token': '21808', 'sector': 'FINANCIAL_SERVICES'},
            {'symbol': 'HDFCLIFE-EQ', 'token': '467', 'sector': 'FINANCIAL_SERVICES'},
            {'symbol': 'TRENT-EQ', 'token': '1964', 'sector': 'RETAIL'},
            {'symbol': 'LTIM-EQ', 'token': '17818', 'sector': 'IT'},
            {'symbol': 'SIEMENS-EQ', 'token': '3150', 'sector': 'CAPITAL_GOODS'},
            {'symbol': 'DLF-EQ', 'token': '14732', 'sector': 'REALTY'},
        ]
        
        logger.info(f"üìä Using Nifty 50 subset: {len(nifty_50_subset)} constituents")
        return nifty_50_subset
    
    def fetch_historical_data(self, symbol: str, token: str, interval: str, 
                            from_date: str, to_date: str) -> pd.DataFrame:
        """Fetch historical candle data from Angel One"""
        try:
            # CRITICAL: Use angelone.in domain (Angel Broking rebranded to Angel One)
            url = "https://apiconnect.angelone.in/rest/secure/angelbroking/historical/v1/getCandleData"
            
            headers = {
                'Authorization': f'Bearer {self.jwt_token}',
                'Content-Type': 'application/json',
                'Accept': 'application/json',
                'X-UserType': 'USER',
                'X-SourceID': 'WEB',
                'X-ClientLocalIP': 'CLIENT_LOCAL_IP',
                'X-ClientPublicIP': 'CLIENT_PUBLIC_IP',
                'X-MACAddress': 'MAC_ADDRESS',
                'X-PrivateKey': self.api_key
            }
            
            payload = {
                "exchange": "NSE",
                "symboltoken": token,
                "interval": interval,
                "fromdate": from_date,
                "todate": to_date
            }
            
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                if data.get('status') and data.get('data'):
                    df = pd.DataFrame(data['data'], 
                                    columns=['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                    df.set_index('timestamp', inplace=True)
                    df = df.astype(float)
                    return df
            
            return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"Error fetching data for {symbol}: {e}")
            return pd.DataFrame()
    
    def screen_stocks(self, screening_date: str, nifty_data: pd.DataFrame) -> List[Dict]:
        """
        LAYER 1 & 2: High-Frequency Screener
        
        Screens Nifty 200 universe at 10:30 AM and returns top 25 candidates
        
        Filters:
        1. Market Alignment: Stock sector + Nifty moving same direction (>0.3%)
        2. Volatility: Daily ATR between 1.0% and 4.0%
        3. Trend Strength: ADX > 25 on 15-min chart
        4. Volume Profile: Current volume > 2.0x average for time-of-day
        
        Returns: List of top 25 stocks with screening scores
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"üîç SCREENING NIFTY 200 AT 10:30 AM")
        logger.info(f"{'='*80}\n")
        
        # Calculate Nifty movement from open
        nifty_open = nifty_data[nifty_data.index.time == time(9, 15)]['Open'].iloc[0]
        nifty_1030 = nifty_data[nifty_data.index.time == self.SCREENING_TIME]['Close'].iloc[-1]
        nifty_move_pct = ((nifty_1030 - nifty_open) / nifty_open) * 100
        
        nifty_direction = 'BULLISH' if nifty_move_pct > self.NIFTY_ALIGNMENT_THRESHOLD else \
                         'BEARISH' if nifty_move_pct < -self.NIFTY_ALIGNMENT_THRESHOLD else 'NEUTRAL'
        
        logger.info(f"üìä Nifty 50: {nifty_move_pct:.2f}% from open ‚Üí {nifty_direction}")
        
        if nifty_direction == 'NEUTRAL':
            logger.warning("‚ö†Ô∏è Nifty is NEUTRAL - reduced screening confidence")
        
        candidates = []
        
        # Fetch end date (today + 1 day for intraday)
        to_date = (datetime.strptime(screening_date, "%Y-%m-%d") + timedelta(days=1)).strftime("%Y-%m-%d %H:%M")
        from_date_15m = (datetime.strptime(screening_date, "%Y-%m-%d") - timedelta(days=5)).strftime("%Y-%m-%d %H:%M")
        from_date_daily = (datetime.strptime(screening_date, "%Y-%m-%d") - timedelta(days=30)).strftime("%Y-%m-%d %H:%M")
        
        for stock in self.NIFTY_200_SYMBOLS:
            symbol = stock['symbol']
            token = stock['token']
            sector = stock.get('sector', 'UNKNOWN')
            
            try:
                # Fetch 15-minute data for ADX and intraday analysis
                df_15m = self.fetch_historical_data(symbol, token, "FIFTEEN_MINUTE", from_date_15m, to_date)
                
                if df_15m.empty:
                    continue
                
                # Fetch daily data for ATR calculation
                df_daily = self.fetch_historical_data(symbol, token, "ONE_DAY", from_date_daily, to_date)
                
                if df_daily.empty:
                    continue
                
                # ===== FILTER 1: Market Alignment =====
                stock_open = df_15m[df_15m.index.time == time(9, 15)]['Open'].iloc[0]
                stock_1030 = df_15m[df_15m.index.time == self.SCREENING_TIME]['Close'].iloc[-1]
                stock_move_pct = ((stock_1030 - stock_open) / stock_open) * 100
                
                # Check alignment with Nifty direction
                if nifty_direction == 'BULLISH' and stock_move_pct < self.NIFTY_ALIGNMENT_THRESHOLD:
                    continue
                elif nifty_direction == 'BEARISH' and stock_move_pct > -self.NIFTY_ALIGNMENT_THRESHOLD:
                    continue
                
                # ===== FILTER 2: Volatility (ATR) =====
                df_daily['ATR'] = ta.volatility.average_true_range(
                    df_daily['High'], df_daily['Low'], df_daily['Close'], window=14
                )
                latest_atr = df_daily['ATR'].iloc[-1]
                latest_close = df_daily['Close'].iloc[-1]
                atr_percent = (latest_atr / latest_close) * 100
                
                if not (self.ATR_MIN_PERCENT <= atr_percent <= self.ATR_MAX_PERCENT):
                    continue
                
                # ===== FILTER 3: Trend Strength (ADX) =====
                adx_indicator = ta.trend.ADXIndicator(
                    df_15m['High'], df_15m['Low'], df_15m['Close'], window=14
                )
                df_15m['ADX'] = adx_indicator.adx()
                
                latest_adx = df_15m['ADX'].iloc[-1]
                
                if latest_adx < self.ADX_MIN_TRENDING:
                    continue
                
                # ===== FILTER 4: Volume Profile =====
                # Calculate average volume for 10:30 AM time slot over past 20 days
                df_15m['Time'] = df_15m.index.time
                historical_1030_volume = df_15m[df_15m['Time'] == self.SCREENING_TIME]['Volume'].tail(20).mean()
                
                current_cumulative_volume = df_15m[df_15m.index.date == df_15m.index.date[-1]]['Volume'].sum()
                
                volume_ratio = current_cumulative_volume / historical_1030_volume if historical_1030_volume > 0 else 0
                
                if volume_ratio < self.VOLUME_MULTIPLIER:
                    continue
                
                # ===== PASSED ALL FILTERS - Add to candidates =====
                score = (
                    abs(stock_move_pct) * 0.3 +  # 30% weight on momentum
                    latest_adx * 0.3 +  # 30% weight on trend strength
                    volume_ratio * 0.2 +  # 20% weight on volume
                    (1 / atr_percent) * 0.2  # 20% weight on stability (inverse ATR)
                )
                
                candidates.append({
                    'symbol': symbol,
                    'token': token,
                    'sector': sector,
                    'move_pct': stock_move_pct,
                    'atr_pct': atr_percent,
                    'adx': latest_adx,
                    'volume_ratio': volume_ratio,
                    'score': score,
                    'data_15m': df_15m,
                    'data_daily': df_daily
                })
                
                logger.info(f"‚úÖ {symbol}: Move={stock_move_pct:.2f}%, ATR={atr_percent:.2f}%, "
                          f"ADX={latest_adx:.1f}, Vol={volume_ratio:.1f}x, Score={score:.2f}")
                
            except Exception as e:
                logger.error(f"‚ùå Error screening {symbol}: {e}")
                continue
        
        # Sort by score and take top 25
        candidates.sort(key=lambda x: x['score'], reverse=True)
        top_25 = candidates[:self.TOP_N_CANDIDATES]
        
        logger.info(f"\n{'='*80}")
        logger.info(f"üéØ TOP 25 CANDIDATES SELECTED (from {len(candidates)} qualified)")
        logger.info(f"{'='*80}\n")
        
        for i, candidate in enumerate(top_25, 1):
            logger.info(f"{i:2d}. {candidate['symbol']:<20} "
                       f"Score: {candidate['score']:6.2f} | "
                       f"Move: {candidate['move_pct']:+6.2f}% | "
                       f"ADX: {candidate['adx']:5.1f} | "
                       f"Vol: {candidate['volume_ratio']:4.1f}x")
        
        return top_25
    
    def calculate_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calculate all technical indicators for strategy execution"""
        # VWAP
        df['Date'] = df.index.date
        def calc_vwap_group(group):
            typical_price = (group['High'] + group['Low'] + group['Close']) / 3
            vwap = (typical_price * group['Volume']).cumsum() / group['Volume'].cumsum()
            return vwap
        
        vwap_values = []
        for date, group in df.groupby('Date'):
            vwap = calc_vwap_group(group)
            vwap_values.append(vwap)
        
        df['VWAP'] = pd.concat(vwap_values)
        
        # EMAs
        df['EMA20'] = ta.trend.ema_indicator(df['Close'], window=self.EMA_20_PERIOD)
        df['EMA50'] = ta.trend.ema_indicator(df['Close'], window=50)
        df['EMA200'] = ta.trend.ema_indicator(df['Close'], window=200)
        
        # ADX
        adx_indicator = ta.trend.ADXIndicator(df['High'], df['Low'], df['Close'], window=14)
        df['ADX'] = adx_indicator.adx()
        
        # RSI
        df['RSI'] = ta.momentum.rsi(df['Close'], window=14)
        
        # ATR
        df['ATR'] = ta.volatility.average_true_range(df['High'], df['Low'], df['Close'], window=14)
        
        df.drop('Date', axis=1, inplace=True, errors='ignore')
        
        return df
    
    def run_backtest_with_screener(self, screening_date: str, initial_capital: float = 100000) -> Dict:
        """
        Complete backtest workflow:
        1. Screen Nifty 200 at 10:30 AM
        2. Select top 25 candidates
        3. Run Alpha-Ensemble strategy on selected stocks
        4. Calculate performance metrics with expectancy (Œ¶)
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"üöÄ ALPHA-ENSEMBLE BACKTEST WITH DYNAMIC SCREENER")
        logger.info(f"{'='*80}")
        logger.info(f"Date: {screening_date}")
        logger.info(f"Initial Capital: ‚Çπ{initial_capital:,.2f}\n")
        
        # Fetch Nifty 50 data for market alignment
        to_date = (datetime.strptime(screening_date, "%Y-%m-%d") + timedelta(days=1)).strftime("%Y-%m-%d %H:%M")
        from_date = (datetime.strptime(screening_date, "%Y-%m-%d") - timedelta(days=5)).strftime("%Y-%m-%d %H:%M")
        
        nifty_data = self.fetch_historical_data('NIFTY 50', '99926000', 'FIVE_MINUTE', from_date, to_date)
        
        if nifty_data.empty:
            logger.error("‚ùå Failed to fetch Nifty data - cannot proceed with screening")
            return {'trades': [], 'capital': initial_capital}
        
        # LAYER 1 & 2: Screen for top 25 candidates
        top_25_candidates = self.screen_stocks(screening_date, nifty_data)
        
        if not top_25_candidates:
            logger.warning("‚ö†Ô∏è No candidates passed screening criteria")
            return {'trades': [], 'capital': initial_capital}
        
        # LAYER 3 & 4: Run Alpha-Ensemble strategy on selected stocks
        logger.info(f"\n{'='*80}")
        logger.info(f"üéØ EXECUTING ALPHA-ENSEMBLE ON TOP 25 CANDIDATES")
        logger.info(f"{'='*80}\n")
        
        all_trades = []
        capital = initial_capital
        
        for candidate in top_25_candidates:
            symbol = candidate['symbol']
            df_5m = candidate['data_15m']  # Use 15m data (already fetched)
            
            # Calculate indicators
            df_5m = self.calculate_indicators(df_5m)
            
            # Run strategy logic (retest entry)
            trades = self._execute_strategy_logic(symbol, df_5m, capital, screening_date)
            
            for trade in trades:
                # Apply slippage
                trade['pnl'] *= (1 - self.SLIPPAGE_PERCENT / 100)
                capital += trade['pnl']
                all_trades.append(trade)
        
        # Calculate performance metrics
        return self._calculate_performance(all_trades, initial_capital, capital)
    
    def _execute_strategy_logic(self, symbol: str, df: pd.DataFrame, capital: float, date: str) -> List[Dict]:
        """
        LAYER 3: Retest Entry Logic (Sniper Execution)
        
        - Establish Defining Range (9:30-10:30 AM)
        - Wait for breakout
        - Enter on pullback to VWAP/EMA20 (retest)
        - Manage with 2.5:1 R:R and break-even trailing
        """
        trades = []
        
        # Implementation would be similar to alpha_ensemble_strategy.py
        # but with the retest logic specifically tuned for screened candidates
        
        # (Full implementation omitted for brevity - use existing alpha_ensemble logic)
        
        return trades
    
    def _calculate_performance(self, trades: List[Dict], initial_capital: float, final_capital: float) -> Dict:
        """
        Calculate comprehensive performance metrics including:
        - Win Rate
        - Profit Factor
        - Expectancy (Œ¶)
        - Max Drawdown
        - Sharpe Ratio
        """
        if not trades:
            return {
                'trades': [],
                'total_trades': 0,
                'win_rate': 0,
                'profit_factor': 0,
                'expectancy': 0,
                'max_drawdown': 0,
                'final_capital': initial_capital,
                'total_return': 0
            }
        
        winning_trades = [t for t in trades if t['pnl'] > 0]
        losing_trades = [t for t in trades if t['pnl'] <= 0]
        
        win_rate = (len(winning_trades) / len(trades)) * 100
        
        total_profit = sum(t['pnl'] for t in winning_trades)
        total_loss = abs(sum(t['pnl'] for t in losing_trades))
        
        profit_factor = (total_profit / total_loss) if total_loss > 0 else 0
        
        # Expectancy (Œ¶) = (Win Rate √ó Avg Win) - (Loss Rate √ó Avg Loss)
        avg_win = total_profit / len(winning_trades) if winning_trades else 0
        avg_loss = total_loss / len(losing_trades) if losing_trades else 0
        loss_rate = (len(losing_trades) / len(trades)) * 100
        
        expectancy = (win_rate/100 * avg_win) - (loss_rate/100 * avg_loss)
        
        # Calculate max drawdown
        running_capital = initial_capital
        peak_capital = initial_capital
        max_drawdown = 0
        
        for trade in trades:
            running_capital += trade['pnl']
            if running_capital > peak_capital:
                peak_capital = running_capital
            drawdown = ((peak_capital - running_capital) / peak_capital) * 100
            if drawdown > max_drawdown:
                max_drawdown = drawdown
        
        return {
            'trades': trades,
            'total_trades': len(trades),
            'win_rate': win_rate,
            'winning_trades': len(winning_trades),
            'losing_trades': len(losing_trades),
            'profit_factor': profit_factor,
            'expectancy': expectancy,
            'avg_win': avg_win,
            'avg_loss': avg_loss,
            'max_drawdown': max_drawdown,
            'final_capital': final_capital,
            'total_return': ((final_capital - initial_capital) / initial_capital) * 100
        }


def main():
    """
    Example usage of Alpha-Ensemble Screener
    """
    print("\n" + "=" * 80)
    print("ALPHA-ENSEMBLE STRATEGY WITH DYNAMIC NIFTY 200 SCREENER")
    print("=" * 80)
    print("\nEnter your Angel One credentials:")
    
    client_code = input("Client Code: ").strip()
    password = input("Password/MPIN: ").strip()
    totp = input("TOTP Code: ").strip()
    api_key = input("API Key: ").strip()
    
    # Authenticate
    import requests
    url = "https://apiconnect.angelone.in/rest/auth/angelbroking/user/v1/loginByPassword"
    
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
        'X-UserType': 'USER',
        'X-SourceID': 'WEB',
        'X-ClientLocalIP': 'CLIENT_LOCAL_IP',
        'X-ClientPublicIP': 'CLIENT_PUBLIC_IP',
        'X-MACAddress': 'MAC_ADDRESS',
        'X-PrivateKey': api_key
    }
    
    payload = {
        "clientcode": client_code,
        "password": password,
        "totp": totp
    }
    
    response = requests.post(url, json=payload, headers=headers)
    
    if response.status_code == 200:
        data = response.json()
        if data.get('status') and data.get('data'):
            jwt_token = data['data']['jwtToken']
            print("‚úÖ Authentication successful!")
        else:
            print("‚ùå Authentication failed")
            return
    else:
        print("‚ùå Authentication failed")
        return
    
    # Create screener instance
    screener = AlphaEnsembleScreener(api_key, jwt_token)
    
    # Run backtest with screening
    backtest_date = input("\nEnter backtest date (YYYY-MM-DD): ").strip()
    
    results = screener.run_backtest_with_screener(
        screening_date=backtest_date,
        initial_capital=100000
    )
    
    # Print results
    print("\n" + "=" * 80)
    print("PERFORMANCE SUMMARY")
    print("=" * 80)
    print(f"\nüí∞ CAPITAL:")
    print(f"   Initial: ‚Çπ{100000:,.2f}")
    print(f"   Final:   ‚Çπ{results['final_capital']:,.2f}")
    print(f"   Return:  {results['total_return']:.2f}%")
    print(f"\nüìä TRADE STATISTICS:")
    print(f"   Total Trades:    {results['total_trades']}")
    print(f"   Winning Trades:  {results['winning_trades']}")
    print(f"   Losing Trades:   {results['losing_trades']}")
    print(f"   Win Rate:        {results['win_rate']:.2f}%")
    print(f"\nüìà PERFORMANCE METRICS:")
    print(f"   Profit Factor:   {results['profit_factor']:.2f}")
    print(f"   Expectancy (Œ¶):  ‚Çπ{results['expectancy']:,.2f}")
    print(f"   Avg Win:         ‚Çπ{results['avg_win']:,.2f}")
    print(f"   Avg Loss:        ‚Çπ{results['avg_loss']:,.2f}")
    print(f"   Max Drawdown:    {results['max_drawdown']:.2f}%")
    print("=" * 80)


if __name__ == "__main__":
    main()
